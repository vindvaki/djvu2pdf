#!/bin/bash


#
# Set up paths
# 

initial_directory=$(pwd)
file_in=$(readlink -f "$1")
file_out=$(readlink -f "$2")

#
# Set up the temporary storage
# 

tmpdir=$(mktemp -d)
cd "$tmpdir" || exit 0

echo "Using $tmpdir for temporary files."

function cleanup() 
{
    rm -rf "$tmpdir"
    cd "$initial_directory" || exit 0
}
trap "cleanup" EXIT # makes sure we clean up after ourselves

#
# Extract raw pages and text
#

ddjvu -verbose -eachpage -format=tiff "$file_in" tmp_page_%04d.tiff
num_pages=$(djvused -e 'n' "$file_in")

echo "    **** Processing $num_pages pages"

# OCR content needs to have one html file per page for `pdfbeads`;
# `djvu2hocr` is capable of extracting it all at once, but then it
# goes into one big file which we would need to split afterwards,
# this would require html parsing, which is just too much.  The
# s/ocrx/ocr/g substitution is a small hack to make `pdfbeads`
# understand the output from `djvu2hocr`.

for i in $(seq -f "%04.0f" 1 "$num_pages"); do
    djvu2hocr "$1" -p "$i" | sed 's/ocrx/ocr/g' > tmp_page_"${i}".html
done

#
# Generate the TOC
#

echo "Extracting the TOC."
djvused -e 'print-outline' "$file_in" > toc.txt

# The output returned by `djvused` has an s-expression like
# tree structure, which is incompatible with the indentation based
# structure used by `pdfbeads`

echo "Converting the TOC for PDFBeams."
"$initial_directory"/djvu2pdf_toc_parser.py < toc.txt > toc.out.txt


#
# Generate the final PDF
#

pdfbeads --toc toc.out.txt -o output.pdf
mv output.pdf "$file_out"
